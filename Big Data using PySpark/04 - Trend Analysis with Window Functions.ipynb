{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4694bb75-0869-4a46-9b9f-75c8fca4db8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup\n",
    "\n",
    "Make sure you have the files available from previous demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e3c255ce-7851-4850-8ccd-f798372e3da9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This cell sets all the configuration parameters to connect to Azure Data Lake\n",
    "spark.conf.set(\"fs.azure.account.auth.type.<account_name>.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(\"fs.azure.account.oauth.provider.type.<account_name>.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.id.<account_name>.dfs.core.windows.net\", \"****************************\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.secret.<account_name>.dfs.core.windows.net\", \"*******************************\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint.<account_name>.dfs.core.windows.net\", \"https://login.microsoftonline.com/************************/oauth2/token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05dc8896-caea-4f87-8175-6c80d31c6293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Verify that cloud storage is accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "950ffc86-3822-465e-8238-ed8860012cbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"abfss://etl1@dbstoragebbpbs73u57xmm.dfs.core.windows.net/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5ba8c1d-8318-47f6-9ff7-8ed30b6f464d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's load the transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "110d9410-36cc-43cd-b150-c27cdc7ed8ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Path to transactions data\n",
    "parquet_path = \"abfss://etl1@dbstoragebbpbs73u57xmm.dfs.core.windows.net/transactions_data.parquet\"\n",
    "\n",
    "# Load the transactions data\n",
    "df_transactions = spark.read.parquet(parquet_path)\n",
    "\n",
    "# Display the first few rows\n",
    "df_transactions.limit(5).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ce1c1a3-b4a5-4e1f-9f13-928433a1c1f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's do a ranking operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70dd160f-79c6-451d-8701-3f8427fc3539",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Ranking using Window Function. There are 3 types of ranking.\n",
    "# 1. Row Number\n",
    "# 2. Rank\n",
    "# 3. Dense Rank\n",
    "\n",
    "window_spec = Window.partitionBy(F.col('customer_id')).orderBy(F.col('transaction_date').asc())\n",
    "display(window_spec)\n",
    "\n",
    "df_ranked = (\n",
    "    df_transactions\n",
    "        .withColumn('row_number', F.row_number().over(window_spec))\n",
    "        .withColumn('rank', F.rank().over(window_spec))\n",
    "        .withColumn('dense_rank', F.dense_rank().over(window_spec))\n",
    ")\n",
    "\n",
    "df_ranked.limit(100).display()\n",
    "\n",
    "# # Ranking transactions within each customer\n",
    "\n",
    "# # Define a window specification for ranking transactions per customer\n",
    "# window_spec = Window.partitionBy(\"customer_id\").orderBy(F.col(\"transaction_date\").asc())\n",
    "# display(window_spec)\n",
    "\n",
    "# df_ranked = (\n",
    "#     df_transactions\n",
    "#         .withColumn(\"row_number\", F.row_number().over(window_spec))\n",
    "#         .withColumn(\"rank\", F.rank().over(window_spec))\n",
    "#         .withColumn(\"dense_rank\", F.dense_rank().over(window_spec))\n",
    "# )\n",
    "\n",
    "# df_ranked.limit(500).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3085c7c9-adb7-426a-8259-aa3619bafa2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's calculate a rolling average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "542800a2-d95a-4f01-a896-fe664c5ed6f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Moving average of transaction amount\n",
    "\n",
    "# Define a window for a rolling average (7-day window per customer)\n",
    "rolling_window = Window.partitionBy('customer_id').orderBy('transaction_date').rowsBetween(-6, 0)\n",
    "\n",
    "df_rolling_avg = (\n",
    "    df_transactions\n",
    "        .withColumn('rolling_avg_amount', F.avg('amount').over(rolling_window))\n",
    ")\n",
    "\n",
    "\n",
    "df_rolling_avg.limit(500).display()\n",
    "\n",
    "# # Moving average of transaction amount\n",
    "\n",
    "# # Define a window for a rolling average (7-day window per customer)\n",
    "# rolling_window = Window.partitionBy(\"customer_id\").orderBy(F.col(\"transaction_date\")).rowsBetween(-6, 0)\n",
    "\n",
    "# df_rolling_avg = (\n",
    "#     df_transactions\n",
    "#         .withColumn(\"rolling_avg_amount\", F.avg(\"amount\").over(rolling_window))\n",
    "# )\n",
    "\n",
    "# df_rolling_avg.limit(5).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0cc59625-f8da-4a47-a05e-99f14cd5d13a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's calculate a running total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9da7fc5-c6ea-402d-92fb-f81d7cef3210",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Running total of transaction amounts per customer\n",
    "\n",
    "# Define a window for cumulative sum per customer\n",
    "\n",
    "cumulative_window = Window.partitionBy('customer_id').orderBy('transaction_date').rowsBetween(Window.unboundedPreceding,0)\n",
    "\n",
    "df_running_total = (\n",
    "    df_transactions\n",
    "        .withColumn('cumulative_amount', F.sum('amount').over(cumulative_window))\n",
    ")\n",
    "\n",
    "df_running_total.limit(500).display()\n",
    "# # Running total of transaction amounts per customer\n",
    "\n",
    "# # Define a window for cumulative sum per customer\n",
    "# cumulative_window = Window.partitionBy(\"customer_id\").orderBy(F.col(\"transaction_date\")).rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "# df_running_total = (\n",
    "#     df_transactions\n",
    "#         .withColumn(\"cumulative_total\", F.sum(\"amount\").over(cumulative_window))\n",
    "# )\n",
    "\n",
    "# df_running_total.limit(5).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "922413a5-5081-4f8f-90b4-5de48d5af5ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's look at lagging and leading indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29da6451-bdf1-49ff-8b8d-99cf4a0eb50b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Compare each transaction to the previous one (lag) and the next one (lead)\n",
    "\n",
    "df_lag_lead = (\n",
    "    df_transactions\n",
    "        .withColumn(\"previous_transaction_amount\", F.lag(\"amount\", 1).over(window_spec))\n",
    "        .withColumn(\"next_transaction_amount\", F.lead(\"amount\", 1).over(window_spec))\n",
    ")\n",
    "\n",
    "df_lag_lead.limit(5).display()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11e39a38-aea2-418a-be1d-311899720bd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "And we can combine these approaches as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47218a27-f363-4828-9d73-bdda7eb29d05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Combining Multiple Window Functions for Trend Analysis\n",
    "\n",
    "df_trend_analysis = (\n",
    "    df_transactions\n",
    "        .withColumn(\"row_number\", F.row_number().over(window_spec))\n",
    "        .withColumn(\"rolling_avg_amount\", F.avg(\"amount\").over(rolling_window))\n",
    "        .withColumn(\"cumulative_total\", F.sum(\"amount\").over(cumulative_window))\n",
    "        .withColumn(\"previous_transaction_amount\", F.lag(\"amount\", 1).over(window_spec))\n",
    "        .withColumn(\"next_transaction_amount\", F.lead(\"amount\", 1).over(window_spec))\n",
    ")\n",
    "\n",
    "df_trend_analysis.limit(5).display()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04 - Trend Analysis with Window Functions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
