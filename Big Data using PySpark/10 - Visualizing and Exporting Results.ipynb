{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4694bb75-0869-4a46-9b9f-75c8fca4db8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Setup\n",
    "\n",
    "Make sure you have the files available from previous demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "e3c255ce-7851-4850-8ccd-f798372e3da9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# This cell sets all the configuration parameters to connect to Azure Data Lake\n",
    "spark.conf.set(\"fs.azure.account.auth.type.<account_name>.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(\"fs.azure.account.oauth.provider.type.<account_name>.dfs.core.windows.net\", \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.id.<account_name>.dfs.core.windows.net\", \"****************************\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.secret.<account_name>.dfs.core.windows.net\", \"*******************************\")\n",
    "spark.conf.set(\"fs.azure.account.oauth2.client.endpoint.<account_name>.dfs.core.windows.net\", \"https://login.microsoftonline.com/************************/oauth2/token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "05dc8896-caea-4f87-8175-6c80d31c6293",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Verify that cloud storage is accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "950ffc86-3822-465e-8238-ed8860012cbd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(dbutils.fs.ls(\"abfss://etl1@dbstoragebbpbs73u57xmm.dfs.core.windows.net/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32c9bb70-f135-4c4f-8561-2d487aceb989",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's load our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "141ef88d-e165-4620-ab61-3d96b0bf69b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Paths to datasets\n",
    "transactions_path = \"abfss://etl1@dbstoragebbpbs73u57xmm.dfs.core.windows.net/transactions_data.parquet\"\n",
    "customers_path = \"abfss://etl1@dbstoragebbpbs73u57xmm.dfs.core.windows.net/customers_data.parquet\"\n",
    "\n",
    "# Load DataFrames\n",
    "df_transactions = spark.read.parquet(transactions_path)\n",
    "df_customers = spark.read.parquet(customers_path)\n",
    "\n",
    "# Display sample data\n",
    "df_transactions.limit(5).display()\n",
    "df_customers.limit(5).display()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f15c8ca4-715d-4ce8-90bf-91d583ea6265",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's join the dataframes and calculate some aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c3f3509-2b1f-4a75-89a9-c6fcd2170543",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Join the two DataFrames on customer_id\n",
    "df_joined = df_customers.join(df_transactions, on=\"customer_id\", how=\"inner\")\n",
    "\n",
    "# Aggregate the joined data:\n",
    "#   - Count the number of transactions per customer\n",
    "#   - Calculate the average transaction amount\n",
    "#   - Determine the first and last transaction dates\n",
    "df_agg = df_joined.groupBy(\"customer_id\", \"email\").agg(\n",
    "    F.count(\"transaction_id\").alias(\"total_transactions\"),\n",
    "    F.avg(\"amount\").alias(\"avg_transaction_amount\"),\n",
    "    F.min(\"transaction_date\").alias(\"first_transaction_date\"),\n",
    "    F.max(\"transaction_date\").alias(\"last_transaction_date\")\n",
    ")\n",
    "\n",
    "# Grab the top 10\n",
    "df_top_customers = df_agg.orderBy(F.desc(\"total_transactions\")).limit(10)\n",
    "df_top_customers.limit(10).display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e32d793-b5dd-4fac-af08-c1c3b299477d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To use popular Python visuals libraries, we convert to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "270a5438-e9b3-43c6-902d-31b289686379",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Convert the Spark DataFrame to a pandas DataFrame\n",
    "df_pandas = df_top_customers.toPandas()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0f7bf6d3-c603-459f-8c6d-503865795c7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Now let's create a visual with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e269cb73-0a8b-4a6f-9f0c-c69edf74d984",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df_pandas['email'], df_pandas['total_transactions'])\n",
    "plt.xlabel('Customer Name')\n",
    "plt.ylabel('Total Transactions')\n",
    "plt.title('Total Transactions per Customer')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "110cff85-a0cc-4e25-9e06-5cffe72579c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We can try with Plotly Express"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42374658-a193-4324-92ad-091626d66421",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create an interactive scatter plot using Plotly Express\n",
    "fig = px.scatter(\n",
    "    df_pandas,\n",
    "    x=\"total_transactions\",\n",
    "    y=\"avg_transaction_amount\",\n",
    "    text=\"email\",\n",
    "    title=\"Avg Transaction Amount vs Total Transactions\"\n",
    ")\n",
    "fig.update_traces(textposition='top center')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c182560b-bd8a-4248-9011-3a5f0494da5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Let's do another one with seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8af4a834-c05e-4eda-8571-715891bdfa83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert decimal.Decimal columns to float\n",
    "df_pandas[\"total_transactions\"] = df_pandas[\"total_transactions\"].astype(float)\n",
    "df_pandas[\"avg_transaction_amount\"] = df_pandas[\"avg_transaction_amount\"].astype(float)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.regplot(\n",
    "    x=\"total_transactions\",\n",
    "    y=\"avg_transaction_amount\",\n",
    "    data=df_pandas,\n",
    "    scatter_kws={\"s\": 100, \"alpha\": 0.7},\n",
    "    line_kws={\"color\": \"red\"}\n",
    ")\n",
    "plt.xlabel(\"Total Transactions\")\n",
    "plt.ylabel(\"Average Transaction Amount\")\n",
    "plt.title(\"Relationship Between Transaction Volume and Average Amount\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "605e4af6-c291-40ff-98db-eded3a0a595a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "And you can of course export any of the dataframes back out to cloud storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04532bbd-3329-4cb9-ae37-3bb7c133d663",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_top_customers.write.format(\"delta\").mode(\"overwrite\").save(\"abfss://pyspark@warnerdatalake.dfs.core.windows.net/exports/top_customers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7f3981e-4786-4a03-a476-baa8b26e6a61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3810177190744832,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "10 - Visualizing and Exporting Results",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
